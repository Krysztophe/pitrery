<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>pitrery - Installation</title>

    <link rel="stylesheet" href="/css/minimal.css">
    <link rel="stylesheet" href="/css/pygment_trac.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
        <script src="/js/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
	<h1>pitrery</h1>
	<p>Point In Time Recovery tools for PostgreSQL</p>

	<nav>
	  <ul>
	    <li><a href="/">home</a></li>
	    <li><a href="downloads.html">downloads</a></li>
	    <li><a href="documentation.html">documentation</a></li>
	    <li><a href="https://github.com/dalibo/pitrery/">source code</a></li>
	  </ul>
	</nav>
      </header>

      <section>
        <h1 id="introduction">Introduction</h1>

<p>pitrery is a set of Bash scripts to manage Point In Time Recovery
(PITR) backups for PostgreSQL. This is the user manual of pitrery
which, hopefully, will guide you in the process of setting up the
tools to perform you backups.</p>

<h1 id="point-in-time-recovery">Point In Time Recovery</h1>

<p>This section introduces the principles of point in time recovery in
PostgreSQL.</p>

<p>Firstly, it is necessary to know that PostgreSQL always write data
twice.  Every transaction is written to the Write Ahead Log (or WAL)
and the corresponding file is synchronized to disk before PostgreSQL
answers to the user when it is committed.</p>

<p>The Write Ahead Log is divided in segments: these are files of 16MB
each, which names are hex numbers keeping them ordered.  Once
PostgreSQL has filled a number of WAL files, when a timeout occurs or
when a superuser asks it, the engine starts a checkpoint.  The
checkpoint consists of writing all the modification of the data to the
database files.  So data is first written to the WAL, then to the data
files.  The checkpoint permits PostgreSQL to recycle the WAL files.</p>

<p>The purpose of this is to permit crash recovery without losing data.
If PostgreSQL detects that the cluster was not cleanly shut down at
startup, then it enters recovery.  Recovery is applying missing
changes to the database files by reading transactions from the WAL.</p>

<p>Point In Time Recovery is based on those principles: since all the
data changes are always stored in the WAL, it means that we could have
PostgreSQL apply the changes they contain to the database files to let
it know about not yet applied transactions, even if the cluster
database files are in an inconsistent state.  To perform PITR backups,
we need to store the WAL files in a safe place, this is called WAL
archiving, PostgreSQL is able to execute an arbitrary command to
archive a WAL segment.  Then, we need a copy of the database files
along with the position in the WAL where recovery must start, this is
called the base backup.  Finally, the recovery phase is configurable,
allowing to stop at a user defined date and time.  The name, Point In
Time Recovery, comes from this feature of PostgreSQL.</p>

<p>Finally, these features of PostgreSQL are used to create standby
servers. When the WAL files are applied to another server, created
from a base base backup, as soon as they are archived, we get a
replicated server.  While it is possible to setup replication with
pitrery, it is not its purpose. One can do both: backups with pitrery
and replication with other tools.</p>

<h1 id="how-pitrery-works">How pitrery works</h1>

<p>The purpose of pitrery is to manage the archiving of WAL segments and
automate the base backup along with restoring the files and preparing
the recovery to a date and time.  Those two job are independent in the
design of pitrery. This means that you can decide not to use the
archiving script to put WAL files in a safe place, which can be
interesting if you already have WAL based replication set up and you
do not want to replace you archiving script with the one provided by
pitrery.</p>

<p>The archive_xlog script takes care of WAL archiving.  It can use a
configuration file to find where to archive WAL files.  As of version
1.3, archive_xlog no longer try to archive to many places.  Instead,
the user has to integrate it in a already existing archiving script or
simply modify the archive_command parameter of postgresql.conf to make
it archive the WAL files.  archive_xlog can copy and compress WAL
files locally or to another server reachable using SSH.  A
configuration file can be used to reduce the size of the command line
defined in the configuration file of PostgreSQL.</p>

<p>As of version 1.4, options of archive_xlog.conf have been merged to
the configuration file of pitrery.</p>

<p>The management of base backups is divided in four parts, each one using
a standalone script to perform an action: backup, restore, purge and
list.  These action can then be called by pitrery, a wrapper around
those scripts that uses a configuration file to define the backup
options.  The purpose of pitrery and its configuration file is reduce
and simplify the commands needed to perform a particular action.  If
it is well configured, then restore is possible from a simple command
with a few switchs, because the pressure on the person running it can
be high at a time when end-users cannot access the database.</p>

<p>The storage place can be a remote server or the local machine. If is a
remote server, it must accessible using SSH in batch mode (One needs
the setup passphraseless SSH keys to do so).  Using the local machine
as storage space can be useful to backup on a filer, whose filesystems
are mounted locally.</p>

<p>On the backup host, pitrery organizes backed up files the following
way:</p>

<ul>
  <li>
    <p>A backup root directory is used to store everything</p>
  </li>
  <li>
    <p>The backups are then grouped in a directory named with a tag, or
label. This enables to store backups for different servers in the same
backup root directory without mixing them.</p>
  </li>
  <li>
    <p>In the “label” subdirectory, each backup is in a directory named
after the date when it was started, this name is used by the restore
script to find the best candidate for a target date.</p>
  </li>
</ul>

<p>Please note that the archived WAL files can be stored in a directory
inside the label subdirectory as long as its name does not start with
a number, to avoid confusing the restore with a non backup directory.</p>

<h1 id="installation">Installation</h1>

<h2 id="prerequisites">Prerequisites</h2>

<p>pitrery is a set of bash scripts, so bash is needed. Apart from bash,
standard tools found on any Linux server are needed: <code>grep</code>, <code>sed</code>, <code>awk</code>,
<code>tar</code>, <code>gzip</code>, <code>ssh</code>, <code>scp</code>…</p>

<p><code>rsync</code> is needed to archive WAL files over the network on <em>both</em> hosts.</p>

<p>GNU make is also needed to install from the source tarball.</p>

<h2 id="installation-from-the-sources">Installation from the sources</h2>

<p>The latest version of can be downloaded from:</p>

<p>https://dl.dalibo.com/public/pitrery/</p>

<p>First unpack the tarball:</p>

<pre><code>tar xzf pitrery-x.y.tar.gz
</code></pre>

<p>Then, go to the pitrery-x.y directory and edit config.mk to fit your
system. Once done run make (or gmake) to replace the interpreter and
paths in the scripts:</p>

<pre><code>make
</code></pre>

<p>Finally, install it, as root if needed: </p>

<pre><code>make install
</code></pre>

<p>By default, the files are installed in /usr/local:</p>

<ul>
  <li>
    <p>scripts are installed in /usr/local/bin</p>
  </li>
  <li>
    <p>actions used by pitrery are installed in /usr/local/lib/pitrery</p>
  </li>
  <li>
    <p>configuration samples are installed in /usr/local/etc/pitrery</p>
  </li>
</ul>

<h1 id="wal-archiving">WAL Archiving</h1>

<p>Every time PostgreSQL fills a WAL segment, it can run a command to
archive it.  It is an arbitrary command used as the value of the
archive_command parameter in postgresql.conf. PostgreSQL only checks
the return code of the command to know whether it worked or not.</p>

<p>pitrery provides the archive_xlog script to copy and possibly compress
WAL segments either on the local machine or on a remote server
reachable using an SSH connection. It is not mandatory to use it, any
script can be used: the only requirement is to provide a mean for the
restore script to get archived segments.</p>

<p>archive_xlog can use the configuration file named pitr.conf,
which sets up defaults. By default, its location is
/usr/local/etc/pitrery/pitr.conf, which can be overridden on
the command line with -C option. The following parameters can be
configured:</p>

<ul>
  <li>
    <p>ARCHIVE_DIR is the target directory where to put files.</p>
  </li>
  <li>
    <p>ARCHIVE_LOCAL controls whether local copy is performed. When this parameter
is set to “yes”, archive_xlog uses cp to copy the file on a local
path. This path maybe a local filesystem or a remote filesystem mounted
locally.  This parameter can be overridden on the command line with
the -L option.</p>
  </li>
  <li>
    <p>ARCHIVE_HOST is the target hostname or IP address used when copying over
an SSH connection.</p>
  </li>
  <li>
    <p>ARCHIVE_USER can be used to specify a username for the SSH
connection. When not set, the username is the system user used by
PostgreSQL.</p>
  </li>
  <li>
    <p>ARCHIVE_COMPRESS controls if the segment is compressed using
gzip. Compression is enabled by default, it can be disabled on busy
server doing a lot write transaction, this can avoid contention on
archiving.</p>
  </li>
  <li>
    <p>SYSLOG can be set to “yes” to log messages to syslog, otherwise
stderr is used for messages.  SYSLOG_FACILITY and SYSLOG_IDENT can
then by used to store messages in the log file of PostgreSQL when it
is configured to use syslog.</p>
  </li>
</ul>

<p>If archiving is set up to a remote host, this host must be accessible
using SSH in batch mode, meaning that passphraseless access using keys
is to be configured for the system user running PostgreSQL to the
remote host.</p>

<p>Once archive_xlog is configured, PostgreSQL must be setup to use it by
modifying the archive_command parameter in postgresql.conf and
dependent parameters:</p>

<pre><code># If using PostgreSQL &gt;= 9.0, wal_level must be set to archive or hot_standby
# Changing this requires a restart
wal_level = archive

# If using PostgreSQL &gt;= 8.3, archiving must be enabled
# Changing this requires a restart
archive_mode = on

# The archive command using the defaults
archive_command = '/usr/local/bin/archive_xlog %p'

# The archive command with parameters
#archive_command = '/usr/local/bin/archive_xlog -C /path/to/pitr.conf %p'
# or to search /usr/local/etc/pitrery for the configuration:
#archive_command = '/usr/local/bin/archive_xlog -C pitr %p'
</code></pre>

<p>Depending on the version of PostgreSQL, restart the server if
wal_level or archive_mode were changed, otherwise reload it.</p>

<h1 id="tuning-wal-files-compression">Tuning WAL files compression</h1>

<p>By default, <code>archive_xlog</code> uses <code>gzip -4</code> to compress the WAL files
when configured to do so (ARCHIVE_COMPRESS=”yes”). It is possible to
compress more and/or faster by using other compression tools, like
<code>bzip2</code>, <code>pigz</code>, the prerequisites are that the compression program
must accept the -c to output on stdout and the data to compress from
stdin. The compression program can be configured by setting
COMPRESS_BIN in the configuration file. The output filename has a
suffix depending on the program used (e.g. “gz” or “bz2”, etc), it
must be configured using COMPRESS_SUFFIX (without the leading dot),
this suffix is most of the time mandatory for decompression. The
decompression program is then configured using UNCOMPRESS_BIN, this
command must accept a compressed file as its first argument.</p>

<p>For example, the fastest compression is achived with <code>pigz</code>, a
multithreaded gzip:</p>

<p>COMPRESS_BIN=”pigz”
UNCOMPRESS_BIN=”pigz -d”</p>

<p>Or maximum, but slow, compression with the standard <code>bzip2</code>:</p>

<p>COMPRESS_BIN=”bzip2 -9”
COMPRESS_SUFFIX=”bz2”
UNCOMPRESS_BIN=”bunzip”</p>

<p>These three parameters can be configured only inside the configuration
file, not from the command line of <code>archive_xlog</code> and <code>restore_xlog</code>.</p>

<h1 id="using-pitrery-to-manage-backups">Using pitrery to manage backups</h1>

<h2 id="configuration">Configuration</h2>

<p>Once the WAL archiving is setup and properly working, pitrery can
create, restore and manage base backups of the <strong>local</strong> PostgreSQL
cluster. pitrery command syntax is:</p>

<pre><code>pitrery [options] action [action-specific options]
</code></pre>

<p>Each action that can be performed by pitr_migr executes the
corresponding script stored by default in
/usr/local/lib/pitrery. These scripts are standalone, they perform the
action based on the options given on the command line at execution
time.  The purpose of pitrery is to wrap there scripts and provide
them with their command line options based on a configuration file.
This reduces the command line size and try to avoid mistakes at
runtime.</p>

<p>Before using pitrery to backup and manage backups for a specific
PostgreSQL cluster, a configuration file shall be created in the
configuration directory, /usr/local/etc/pitrery by default. This
configuration holds all the information necessary to manage backups for
this cluster. The default configuration file is pitr.conf, containing
all the default parameters.</p>

<p>The easiest way to configure pitrery is to copy the default
configuration file to new name meaningful to our setup:</p>

<pre><code>cd /usr/local/etc/pitrery
cp pitr.conf prod.conf
</code></pre>

<p>We will create a configuration file for the backup of our critical
production server. We edit this file to define the specific
parameters for this PostgreSQL server.</p>

<p>The first parameters configure how to connect to the PostgreSQL server to
backup.  It is needed to run pg_start_backup() and pg_stop_backup() to
let us tell PostgreSQL a backup is being run. pitrery uses the same
variables as the tools of PostgreSQL :</p>

<ul>
  <li>
    <p>PGDATA is the path to the directory storing the cluster</p>
  </li>
  <li>
    <p>PGPSQL is the path to the psql program</p>
  </li>
  <li>
    <p>PostgreSQL access configuration: PGUSER, PGPORT, PGHOST and
PGDATABASE are the well known variables to reach the server.</p>
  </li>
</ul>

<p>If psql is in the PATH, the variable can be commented out to use the
one found in the PATH. If other variables are defined in the
environment, they can be commented out in the file to have pitrery use
them.</p>

<p>The following parameters control the different actions accessible
through pitrery :</p>

<ul>
  <li>
    <p>PGOWNER is the system user which owns the files of the cluster, it
is useful when restoring as root if the user want to restore as
another user.</p>
  </li>
  <li>
    <p>PGXLOG is a path where transaction logs can be stored on restore,
pg_xlog would then be a symbolic link to this path, like <code>initdb -X</code></p>
  </li>
  <li>
    <p>BACKUP_IS_LOCAL tells pitrery that the backups are stored on the
local machine. When set to “yes”, the target host is no longer
needed.</p>
  </li>
  <li>
    <p>BACKUP_DIR is the path to the directory where to store the backups.</p>
  </li>
  <li>
    <p>BACKUP_LABEL is the name of the set of backups, all backups will be
stored in a subdirectory named with this value to let the user store
backups for different servers in the same BACKUP_DIR. This value is
also used in the call to pg_start_backup() with the date appended.</p>
  </li>
  <li>
    <p>BACKUP_HOST is the IP address of the host where backups shall be
stored. BACKUP_USER is the username to use for SSH login, if empty,
the username is the one running pitrery.</p>
  </li>
  <li>
    <p>RESTORE_COMMAND can be used to define the command run by PostgreSQL
when it needs to retrieve a WAL file before applying it in recovery
mode. It is useful when WAL archiving is not performed by
pitrery. When archive_xlog is used, e.g. RESTORE_COMMAND is left
empty, it defaults to a call to restore_xlog and it is not necessary
to set it up here, unless archived WAL files are stored on a
different host than BACKUP_HOST.</p>
  </li>
  <li>
    <p>PURGE_KEEP_COUNT controls how many backups must be kept when purging
old backups.</p>
  </li>
  <li>
    <p>PURGE_OLDER_THAN controls how many <strong>days</strong> backups are kept when
purging. If PURGE_KEEP_COUNT is also set, age based purge will
always leave at least PURGE_KEEP_COUNT backups.</p>
  </li>
  <li>
    <p>ARCHIVE<em>* and SYSLOG</em>* are passed to restore_xlog when
RESTORE_COMMAND is empty. They define the location (either local or
through SSH) where the WAL files are stored.</p>
  </li>
</ul>

<h2 id="hooks">Hooks</h2>

<p>Some user defined commands can be executed, they are given in the
following configuration variables:</p>

<ul>
  <li>
    <p>PRE_BACKUP_COMMAND is run before the backup is started.</p>
  </li>
  <li>
    <p>POST_BACKUP_COMMAND is run after the backup is finished.</p>
  </li>
</ul>

<p>The following variables are then available, to access the PostgreSQL
or the current backup:</p>

<ul>
  <li>
    <p>PITRERY_HOOK is the name of the hook being run</p>
  </li>
  <li>
    <p>PITRERY_PSQL is the psql command line to run SQL statement on the
saved PostgreSQL server</p>
  </li>
  <li>
    <p>PITRERY_DATABASE is the name of the connection database</p>
  </li>
  <li>
    <p>PITRERY_BACKUP_DIR is the full path to the directory of the backup</p>
  </li>
  <li>
    <p>PITRERY_BACKUP_LOCAL can be used to know is SSH is required to access the backup directory</p>
  </li>
  <li>
    <p>PITRERY_SSH_TARGET the user@host part needed to access to backup server</p>
  </li>
</ul>

<h2 id="backup-storage">Backup storage</h2>

<p>As of version 1.5, pitrery offers two storage technics for the base backup.</p>

<p>The first, and historical, is <code>tar</code>, where it creates one compressed
tarball (with gzip) for PGDATA and each tablespace. The <code>tar</code> method
is quite slow and can become difficult to use with bigger database
clusters, however the compression saves a lot of space.</p>

<p>The second is <code>rsync</code>. It synchronizes PGDATA and each tablespace to a
directory inside the backup, and try to optimize data transfer by
hardlinking the files of the previous backup (provided it was done
with the “rsync” method). This method should offer the best speed for
the base backup, and is recommanded for big databases clusters (more
than several hundreds of gigabytes).</p>

<p>The default method is <code>tar</code>. It can be configured by setting the
<code>STORAGE</code> variable to either <code>tar</code> or <code>rsync</code> in the configuration
file.</p>

<h2 id="usage">Usage</h2>

<p>Note: all commands have a -? switch to show their usage details.</p>

<p>The help for pitrery is available by running it with the -h option :</p>

<pre><code>$ pitrery -?
usage: pitrery [options] action [args]
options:
    -c file      Path to the configuration file
    -n           Show the command instead of executing it
    -?           Print help

actions:
    list
    backup
    restore
    purge
</code></pre>

<p>If we want to backup our example production server, the name of the
configuration must given to pitrery with the -c option. The name of
the configuration file, if it is not a path, is searched in the
configuration directory, any file ending with .conf is then taken, for
example :</p>

<pre><code>$ pitrery -c prod action
</code></pre>

<p>This will use the file /usr/local/etc/pitrery/prod.conf. When adding
the -? switch after the action name, pitrery outputs the help of the
action, for example :</p>

<pre><code>$ pitrery backup -?
backup_pitr performs a PITR base backup

Usage:
    backup_pitr [options] [hostname]

Backup options:
    -L              Perform a local backup
    -b dir          Backup directory
    -l label        Backup label, it will be suffixed with the date and time
    -u username     Username for SSH login
    -D dir          Path to $PGDATA
    -s mode         Storage method, tar or rsync

Connection options:
    -P PSQL         path to the psql command
    -h HOSTNAME     database server host or socket directory
    -p PORT         database server port number
    -U NAME         connect as specified database user
    -d DATABASE     database to use for connection

    -?              Print help
</code></pre>

<p>The -n option of pitrery can be used to show the action script
command line that would be runned, but without running it. It is
useful to check if the parameters configured in a particular
configuration file are correct. For example, with the default
configuration file pitr.conf :</p>

<pre><code>$ pitrery -n backup 192.168.0.50
/usr/local/lib/pitrery/backup_pitr -b /var/lib/pgsql/backups \
  -l pitr -D /var/lib/pgsql/data -P psql -h /tmp -p 5432 \
  -U postgres -d postgres 192.168.0.50
</code></pre>

<p>Finally, every configuration parameter defined in the configuration
file can be overridden on the command line by adding the corresponding
switch after the action. For example, if the port of the PostgreSQL is
5433 :</p>

<pre><code>$ pitrery -n backup -p 5433 192.168.0.50
/usr/local/lib/pitrery/backup_pitr -b /var/lib/pgsql/backups \
  -l pitr -D /var/lib/pgsql/data -P psql -h /tmp -p 5433 \
  -U postgres -d postgres 192.168.0.50
</code></pre>

<p>Note: the BACKUP_HOST is not defined in the configuration file used
for the example, this is why the IP address was added after the
“backup” action.</p>

<h2 id="backup">Backup</h2>

<p><strong>Beware that the backup must run on the PostgreSQL server host</strong>,
SSH login is used to <strong>push</strong> data to a backup server, and PostgreSQL
connection options to run SQL <strong>locally</strong>.</p>

<p>To run a backup with pitrery, either a configuration file is needed
or the options must be put on the commandline. The usage of the backup
action is:</p>

<pre><code>$ pitrery backup -?
backup_pitr performs a PITR base backup

Usage:
    backup_pitr [options] [hostname]

Backup options:
    -L              Perform a local backup
    -b dir          Backup base directory
    -l label        Backup label
    -u username     Username for SSH login
    -D dir          Path to $PGDATA
    -s mode         Storage method, tar or rsync

Connection options:
    -P PSQL         path to the psql command
    -h HOSTNAME     database server host or socket directory
    -p PORT         database server port number
    -U NAME         connect as specified database user
    -d DATABASE     database to use for connection

    -?              Print help
</code></pre>

<p>For example, the configuration file for our example production server
is the following:</p>

<pre><code>PGDATA="/home/postgres/postgresql-9.2.4/data"
PGPSQL="/home/postgres/postgresql-9.2.4/bin/psql"
PGUSER="postgres"
PGPORT=5432
PGHOST="/tmp"
PGDATABASE="postgres"
PGOWNER=$PGUSER
BACKUP_IS_LOCAL="no"
BACKUP_DIR="/home/postgres/backups"
BACKUP_LABEL="prod"
BACKUP_HOST=10.100.0.16
BACKUP_USER=
RESTORE_COMMAND=
PURGE_KEEP_COUNT=2
PURGE_OLDER_THAN=
PRE_BACKUP_COMMAND=
POST_BACKUP_COMMAND=
STORAGE="tar"
ARCHIVE_LOCAL="no"
ARCHIVE_HOST=10.100.0.16
ARCHIVE_USER=
ARCHIVE_DIR="/home/postgres/backups/prod/xlog"
ARCHIVE_COMPRESS="yes"
SYSLOG="no"
SYSLOG_FACILITY="local0"
SYSLOG_IDENT="postgres"
STORAGE="tar"
</code></pre>

<p>With those options, pitrery can run a backup:</p>

<pre><code>$ pitrery -c prod backup
INFO: preparing directories in 10.100.0.16:/home/postgres/backups/prod
INFO: listing tablespaces
INFO: starting the backup process
INFO: backing up PGDATA with tar
INFO: archiving /home/postgres/postgresql-9.0.4/data
INFO: backup of PGDATA successful
INFO: backing up tablespace "ts2" with tar
INFO: archiving /home/postgres/postgresql-9.0.4/ts2
INFO: backup of tablespace "ts2" successful
INFO: stopping the backup process
NOTICE:  pg_stop_backup complete, all required WAL segments have been archived
INFO: copying the backup history file
INFO: copying the tablespaces list
INFO: backup directory is 10.100.0.16:/home/postgres/backups/prod/2013.08.28-11.16.30
INFO: done
</code></pre>

<p>If we have a look at the contents of the /home/postgres/backups
directory on the backup host:</p>

<pre><code>/home/postgres/backups
└── prod
    ├── 2013.08.28-11.16.30
    │   ├── backup_label
    │   ├── backup_timestamp
    │   ├── pgdata.tar.gz
    │   ├── tblspc
    │   │   └── t2.tar.gz
    │   └── tblspc_list
    └── xlog
        ├── 000000010000000000000036.gz
        ├── 000000010000000000000037.gz
        ├── 000000010000000000000038.gz
        ├── 000000010000000000000039.gz
        ├── 00000001000000000000003A.gz
        ├── 00000001000000000000003B.gz
        ├── 00000001000000000000003C.00000078.backup.gz
        ├── 00000001000000000000003C.gz
        └── 00000001000000000000003D.gz
</code></pre>

<p>The backup is stored in the <code>prod/2013.08.28-11.16.30</code> diretory of
BACKUP_DIR, “prod” being the label defined by BACKUP_LABEL. The backup
directory is named with the start date and time of the backup. The
<code>backup_timestamp</code> file contains the timestamp value of the stop time
of the backup, which is used by the restore action to find the best
candidate when restoring to a specific date and time and by the purge
action. The directory stores the backup label file of PostgreSQL, a
tarball of the PGDATA directory, tarballs for each tablespace and the
tablespace list with their path. Finally, but no shown in the example,
a <code>conf</code> directory can be created to stored configuration files of the
database cluster (<code>postgresql.conf</code>, <code>pg_hba.conf</code> and
<code>pg_ident.conf</code>) when they are not located inside PGDATA.</p>

<p>Notes:
* Here we have configured archive_xlog to store the WAL files in
  <code>prod/xlog</code> to have them close to the base backups.
* When using the <code>rsync</code> storage method, tarballs are replaced with
  directory with the same base name.</p>

<h2 id="listing-backups">Listing backups</h2>

<p>The list action allow to find the backups for a particular label on
the backup host. For example:</p>

<pre><code>$ pitrery -c prod list
List of backups on 10.100.0.16:

Directory:
  /usr/data/pitrery/backups/pitr13/2013.05.31_11.44.02
Minimum recovery target time:
  2013-05-31 11:44:02 CEST
Tablespaces:

Directory:
  /usr/data/pitrery/backups/pitr13/2013.05.31_11.49.37
Minimum recovery target time:
  2013-05-31 11:49:37 CEST
Tablespaces:
  ts1 /home/pgsql/postgresql-9.1.9/ts1 (24576)
</code></pre>

<p>It lists the directory of each found backup with the date and time
when it was run.</p>

<p>Like the other commands, the options of the list action can be display
by adding the -? option after the action:</p>

<pre><code>$ pitrery list -?
usage: list_pitr [options] [hostname]
options:
    -L              List from local storage
    -u username     Username for SSH login
    -b dir          Backup storage directory
    -l label        Label used when backup was performed

    -?              Print help
</code></pre>

<h2 id="restore">Restore</h2>

<p>The restore action takes a backup and prepares the recovery to restore
to a particular point in time. The target date must be given on the
command line using the -d option. Its format is the one expected by
PostgreSQL: YYYY-mm-DD HH:MM:SS [+-]TZTZ’. The ‘[+-]TZTZ’ is the
timezone offset, it must given as HHMM, .e.g +2h30 would be +0230 and
-7h would be -0700.</p>

<p>This action perform the following steps:</p>

<ul>
  <li>
    <p>Find the newest possible backup from the store.</p>
  </li>
  <li>
    <p>Retrieve and extract the contents of PGDATA and the tablespaces.</p>
  </li>
  <li>
    <p>Create a recovery.conf file for PostgreSQL.</p>
  </li>
  <li>
    <p>Optionally, restore the saved configuration files in
PGDATA/restored_config_files if they were outside PGDATA at the time
of the backup.</p>
  </li>
  <li>
    <p>Optinally, create a script to update the catalog when paths to
tablespaces have changed, for PostgreSQL &lt;= 9.1.</p>
  </li>
</ul>

<p>The restore will only work if the target destination directory (PGDATA
in the configuration file of pitrery) and the directories used by
tablespaces exist or can be created, are writable and empty. It is
important to prepare those directories before running the restore.</p>

<p>When specifiying a target date, it will be used in the
$PGDATA/recovery.conf file as value for the recovery_target_time
parameter.</p>

<p>Unless RESTORE_COMMAND is defined to something else, the restore_xlog
script will be used by PostgreSQL to retrieve archived WAL files. The
purpose of this script is to find, copy on PostgreSQL server, and
uncompress the archived WAL file asked by PostgreSQL.  its behavior is
controlled from its command line options, for example:</p>

<pre><code>restore_xlog -h HOST -d ARCHIVE_DIR %f %p
</code></pre>

<p>The restore script uses options values from the configuration, which
can be tweaked on the command line. Beware that some options have
different names between restore_xlog and the restore action.</p>

<p>Let’s say the target directories are ready for a restore run by the
postgres user, the restore can be started with pitrery on an example
production server:</p>

<pre><code>$ pitrery -c prod restore -d '2013-06-01 13:00:00 +0200'
INFO: searching backup directory
INFO: searching for tablespaces information
INFO: 
INFO: backup directory:
INFO:   /home/pgsql/postgresql-9.1.9/pitr/prod/2013.06.01_12.15.38
INFO: 
INFO: destinations directories:
INFO:   PGDATA -&gt; /home/pgsql/postgresql-9.1.9/data
INFO:   tablespace "ts1" -&gt; /home/pgsql/postgresql-9.1.9/ts1 (relocated: no)
INFO:   tablespace "ts2" -&gt; /home/pgsql/postgresql-9.1.9/ts2 (relocated: no)
INFO: 
INFO: recovery configuration:
INFO:   target owner of the restored files: postgres
INFO:   restore_command = '/usr/local/bin/restore_xlog -L -d /home/pgsql/postgresql-9.1.9/archives %f %p'
INFO:   recovery_target_time = '2013-06-01 13:00:00 +0200'
INFO: 
INFO: checking if /home/pgsql/postgresql-9.1.9/data is empty
INFO: checking if /home/pgsql/postgresql-9.1.9/ts1 is empty
INFO: checking if /home/pgsql/postgresql-9.1.9/ts2 is empty
INFO: extracting PGDATA to /home/pgsql/postgresql-9.1.9/data
INFO: extracting tablespace "ts1" to /home/pgsql/postgresql-9.1.9/ts1
INFO: extracting tablespace "ts2" to /home/pgsql/postgresql-9.1.9/ts2
INFO: preparing pg_xlog directory
INFO: preparing recovery.conf file
INFO: done
INFO: 
INFO: please check directories and recovery.conf before starting the cluster
INFO: and do not forget to update the configuration of pitrery if needed
INFO:
</code></pre>

<p>The restore script finds that the backup to be restored is located in
/home/pgsql/postgresql-9.1.9/pitr/prod/2013.06.01_12.15.38 on our backup
server. It then extracts everything, including the tablespaces
and prepares the recovery.conf at the root of $PGDATA. The script tell
the user to check everything before starting the PostgreSQL cluster:
This behavior is intentionnal, it allows the user to modify parameters
of PostgreSQL or change how the recovery is configured in
recovery.conf.</p>

<p>When everything is fine, the PostgreSQL can be started, it will apply
the archived WAL files until the target date is reached or until all
archived WAL files are consumed if no target date was specified.</p>

<p>If unsure about the options to give for a restore, use the -n switch
of the restore action to make it stop after showing the informations.</p>

<p>Furthermore, it possible choose the target directories when restoring,
use -D switch to set the target directory for PGDATA, and one to many
-t switches to relocate the tablespaces to other directories. The
format of the value of a -t option is tablespace_name:new_directory.</p>

<p>One -t option apply to one tablespace. For example:</p>

<pre><code>$ pitrery -c prod restore -d '2013-06-01 13:00:00 +0200' \
  -D /home/pgsql/postgresql-9.1.9/data_restore \
  -t ts1:/home/pgsql/postgresql-9.1.9/ts1_restore 
INFO: searching backup directory
INFO: searching for tablespaces information
INFO: 
INFO: backup directory:
INFO:   /home/pgsql/postgresql-9.1.9/pitr/pitr13/2013.06.01_12.15.38
INFO: 
INFO: destinations directories:
INFO:   PGDATA -&gt; /home/pgsql/postgresql-9.1.9/data_restore
INFO:   tablespace "ts1" -&gt; /home/pgsql/postgresql-9.1.9/ts1_restore (relocated: yes)
INFO:   tablespace "ts2" -&gt; /home/pgsql/postgresql-9.1.9/ts2 (relocated: no)
INFO: 
INFO: recovery configuration:
INFO:   target owner of the restored files: orgrim
INFO:   restore_command = '/usr/local/bin/restore_xlog -L -d /home/pgsql/postgresql-9.1.9/archives %f %p'
INFO:   recovery_target_time = '2013-06-01 13:00:00 +0200'
INFO: 
INFO: creating /home/pgsql/postgresql-9.1.9/data_restore
INFO: setting permissions of /home/pgsql/postgresql-9.1.9/data_restore
INFO: creating /home/pgsql/postgresql-9.1.9/ts1_restore
INFO: setting permissions of /home/pgsql/postgresql-9.1.9/ts1_restore
INFO: checking if /home/pgsql/postgresql-9.1.9/ts2 is empty
INFO: extracting PGDATA to /home/pgsql/postgresql-9.1.9/data_restore
INFO: extracting tablespace "ts1" to /home/pgsql/postgresql-9.1.9/ts1_restore
INFO: extracting tablespace "ts2" to /home/pgsql/postgresql-9.1.9/ts2
INFO: preparing pg_xlog directory
INFO: preparing recovery.conf file
INFO: done
INFO: 
INFO: please check directories and recovery.conf before starting the cluster
INFO: and do not forget to update the configuration of pitrery if needed
INFO: 
WARNING: locations of tablespaces have changed, after recovery update the catalog with:
WARNING:   /home/pgsql/postgresql-9.1.9/data_restore/update_catalog_tablespaces.sql
</code></pre>

<p>In the above example, the PGDATA has been changed along with the path
of the ts1 tablespace. Since the version of PostgreSQL is 9.1, pitrery
creates a SQL file with the <code>UPDATE</code> statements needed to change the
<code>spclocation</code> column of <code>pg_tablespace</code> (this columns has been removed
as of 9.2). This script must be run as a superuser role on the
restored cluster after the recovery.</p>

<p>Again, if unsure, run the restore action with the -n switch to display
what would be done. The options of restore are:</p>

<pre><code>$ pitrery restore -?
restore_pitr performs a PITR restore

Usage:
    restore_pitr [options] [hostname]

Restore options:
    -L              Restore from local storage
    -u username     Username for SSH login to the backup host
    -b dir          Backup storage directory
    -l label        Label used when backup was performed
    -D dir          Path to target $PGDATA
    -x dir          Path to the xlog directory (only if outside $PGDATA)
    -d date         Restore until this date
    -O user         If run by root, owner of the files
    -t tblspc:dir   Change the target directory of tablespace "ts"
                      this switch can be used many times
    -n              Dry run: show restore information only

Archived WAL files options:
    -A              Force the use of local archives
    -h host         Host storing WAL files
    -U username     Username for SSH login to WAL storage host
    -X dir          Path to the archived xlog directory
    -r cli          Command line to use in restore_command
    -C              Do not uncompress WAL files
    -S              Send messages to syslog
    -f facility     Syslog facility
    -i ident        Syslog ident

    -?              Print help
</code></pre>

<h2 id="removing-old-backups">Removing old backups</h2>

<p>The purge action can remove old backups according to a policy based on
the number of backups to keep and/or their age in days. If the maximum
number of backups and the maximum age are set, the number is always
respected: it prevents the user from removing all backups if all of
them are too old. The purge script will also try to remove unnecessary
archived WAL files, provided it can reach the location where they are
stored.</p>

<p>The -m on the command line or the PURGE_KEEP_COUNT in the
configuration file define the maximum number of backups to keep. The
-d on the command line or the PURGE_OLDER_THAN in the configuration
file is used to define the maximum age in days.</p>

<p>For example, we have two backups on the store and we want to keep only
one, while PURGE_KEEP_COUNT=2:</p>

<pre><code>$ pitrery -c prod purge -m 1
INFO: searching backups
INFO: purging /home/postgres/backups/prod/2011.08.17-11.16.30
INFO: purging WAL files older than 000000020000000000000060
INFO: 75 old WAL file(s) removed
INFO: done
</code></pre>



      </section>

      <footer>
	<p>Copyright &copy; 2011-2013 Nicolas Thauvin.</p>
	<p>Sponsored by <a href="http://dalibo.com">Dalibo</a>, developed and maintained by <a href="http://orgrim.net/">Nicolas Thauvin</a></p>
	<p><small>Theme based on minimal by <a href="https://github.com/orderedlist">orderedlist</a> licencsed under CC-BY-SA 3.0 Unported</small></p>
      </footer>
    </div> <!-- /container -->
    <script src="/js/scale.fix.js"></script>
  </body>
</html>
